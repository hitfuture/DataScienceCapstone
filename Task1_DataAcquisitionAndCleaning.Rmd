---
title: "Task 1 - Data acquisition and cleaning"
author: "Brett Taylor"
date: "December 9, 2015"
output: word_document
---

#Data Acquisition
The data source is from the Coursera site.  https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip  There is a set of files in multiple languages.    
* Twitter
* News
* Blog Posts


#Clean Data - Remove Profanities
We need to ensure profanities are not allowed.   We utilized the Google What You Love data source captured by Jamie W. on GitHub to create a list of stop words.  The data source is here, and required some cleaning up since it did not meet JSON standards: https://gist.github.com/jamiew/1112488.   Note that this includes very profane words and should not be shared with people that will be offended.


```{r getBadWords,warning=FALSE}
library(RJSONIO)
library(tm)
curseStops  <- names(fromJSON("./data/google_twunter_lol.json"))
curseCorp <- VCorpus(VectorSource(curseStops))
#print(sample(curseStops,100))
```

#Clean and Process Data
We need to tokenize the text based data.  

```{r writeCorpusDataSets,cache=TRUE}
library(tm)
source("sampleData.R")

writeCorpusDataSets("./data/en_US.blogs.txt")
writeCorpusDataSets("./data/en_US.news.txt")
writeCorpusDataSets("./data/en_US.twitter.txt")
```

```{r buildModel1,warning=FALSE}
source("runModel.R")
source("buildModel.R")


blogsTermMap <- buildTermMap("./data/en_US.blogs.train.txt")
twitterTermMap<- buildTermMap("./data/en_US.twitter.train.txt")
newsTermMap<- buildTermMap("./data/en_US.news.train.txt")


```

#The need for spell checking

I think that when a user types in words into the window, they will need to have their word spell checked, and corrected to that predictions are accurate.  The corpus may have variation.

#Blog
 
```{r blogCloud,warning=FALSE,eval=FALSE}
    
library("RWeka")
library(wordcloud)
library(knitr)
options(mc.cores=1)
map <- blogsTermMap
tdmap1  <- buildUnigramMap(map)
tdmap2  <- buildBigramMap(map)
tdmap3 <- buildTrigramMap(map)
tdmap4 <- buildQuadgramMap(map)


blog.d1 <- buildFrequencyDataSet(tdmap1)
blog.d2 <- buildFrequencyDataSet(tdmap2)
blog.d3 <- buildFrequencyDataSet(tdmap3)
blog.d4 <- buildFrequencyDataSet(tdmap4)


#inspect(tdmap1[,1])
#object.size(tdmap4[,1])
kable(head(blog.d1,20),caption = "Blog Unigram Frequency - Top 20")

kable(head(blog.d2,20),caption = "Blog Bigram Frequency - Top 20")

kable(head(blog.d3,20),caption = "Blog Trigram Frequency - Top 20")

kable(head(blog.d4,20),caption = "Blog Quadgram Frequency - Top 20")

pal <- brewer.pal(6,"Dark2")
pal <- pal[-(1)]
wordcloud(blog.d1$word, blog.d1$freq,scale = c(4,0.4),colors =  pal,max.words = 300)

wordcloud(blog.d2$word, blog.d2$freq,scale = c(4,0.4),colors =  pal,max.words = 75)

wordcloud(blog.d3$word, blog.d3$freq,scale = c(3.3,0.4),colors =  pal,max.words = 45)
wordcloud(blog.d4$word, blog.d4$freq,scale = c(3.1,0.2),colors =  pal,max.words = 35)

```

##Twitter 

```{r twitterCloud,warning=FALSE,eval=FALSE}
    
map <- twitterTermMap
tdmap1  <- buildUnigramMap(map)
tdmap2  <- buildBigramMap(map)
tdmap3 <- buildTrigramMap(map)
tdmap4 <- buildQuadgramMap(map)

twitter.d1 <- buildFrequencyDataSet(tdmap1)
twitter.d2 <- buildFrequencyDataSet(tdmap2)
twitter.d3 <- buildFrequencyDataSet(tdmap3)
twitter.d4 <- buildFrequencyDataSet(tdmap4)


#inspect(tdmap)
#object.size(tdmap)
kable(head(twitter.d1,20),caption = "Twitter Unigram Frequency - Top 20")

kable(head(twitter.d2,20),caption = "Twitter Bigram Frequency - Top 20")

kable(head(twitter.d3,20),caption = "Twitter Trigram Frequency - Top 20")

kable(head(twitter.d4,20),caption = "Twitter Quadgram Frequency - Top 20")

pal <- brewer.pal(6,"Dark2")
pal <- pal[-(1)]
wordcloud(twitter.d1$word, twitter.d1$freq,scale = c(4,0.4),colors =  pal,max.words = 300)

wordcloud(twitter.d2$word, twitter.d2$freq,scale = c(4,0.4),colors =  pal,max.words = 100)

wordcloud(twitter.d3$word, twitter.d3$freq,scale = c(3.5,0.4),colors =  pal,max.words = 50)

wordcloud(twitter.d4$word, twitter.d4$freq,scale = c(3,0.2),colors =  pal,max.words = 35)

```

##News

```{r newsCloud,warning=FALSE,eval=FALSE}
map <- newsTermMap
tdmap1  <- buildUnigramMap(map)
tdmap2  <- buildBigramMap(map)
tdmap3 <- buildTrigramMap(map)
tdmap4 <- buildQuadgramMap(map)

news.d1 <- buildFrequencyDataSet(tdmap1)
news.d2 <- buildFrequencyDataSet(tdmap2)
news.d3 <- buildFrequencyDataSet(tdmap3)
news.d4 <- buildFrequencyDataSet(tdmap4)
gc()

#inspect(tdmap)
#object.size(tdmap)
kable(head(news.d1,20),caption = "Twitter Unigram Frequency - Top 20")

kable(head(news.d2,20),caption = "Twitter Bigram Frequency - Top 20")

kable(head(news.d3,20),caption = "Twitter Trigram Frequency - Top 20")

kable(head(news.d4,20),caption = "Twitter Quadgram Frequency - Top 20")

pal <- brewer.pal(6,"Dark2")
pal <- pal[-(1)]
wordcloud(news.d1$word, news.d1$freq,scale =  c(8,.6),colors =  pal,max.words = 300)

wordcloud(news.d2$word, news.d2$freq,scale = c(5,0.4),colors =  pal,max.words = 100)

wordcloud(news.d3$word, news.d3$freq,scale = c(3.8,0.3),colors =  pal,max.words = 50)

wordcloud(news.d4$word, news.d4$freq,scale = c(3,0.2),colors =  pal,max.words = 35)

   
```

###Final Map
```{r finalMaps, warning=FALSE}
library(slam)
maps <- c(blogsTermMap,twitterTermMap,newsTermMap)
tdMapsUnigram <- buildUnigramMap(maps)
#tdMapsUnigram2 <- removeSparseTerms(tdMapsUnigram,.999)
tdMapsUnigram <- rollup(tdMapsUnigram,2,na.rm=TRUE,FUN = sum)
frequencyUnigramDF <- buildFrequencyDataSet(tdMapsUnigram)
#frequencyUnigramDF <- frequencyUnigramDF%>%group_by(word,w_0)%>%summarize(freq)%>%ungroup()

tdMapsBigram <- buildBigramMap(maps)
#tdMapsBigram <- rollup(tdMapsBigram,2,na.r=TRUE,FUN=sum)
tdMapsBigram2 <- removeSparseTerms(tdMapsBigram,.99999)
frequencyBigramDF <- buildFrequencyDataSet(tdMapsBigram)
frequencyBigramDF <- computeProbability(frequencyBigramDF, frequencyUnigramDF)


tdMapsTrigram <- buildTrigramMap(maps)
tdMapsTrigram2 <- removeSparseTerms(tdMapsTrigram,.99999)
frequencyTrigramDF <- buildFrequencyDataSet(tdMapsTrigram2)
frequencyTrigramDF <- computeProbability(frequencyTrigramDF, frequencyUnigramDF)

tdMapsQuadgram <- buildQuadgramMap(maps)
tdMapsQuadgram2 <- removeSparseTerms(tdMapsQuadgram,.99999)
frequencyQuadgramDF <- buildFrequencyDataSet(tdMapsQuadgram2)

frequencyQuadgramDF <- computeProbability(frequencyQuadgramDF, frequencyUnigramDF)


pal <- brewer.pal(6,"Dark2")
pal <- pal[-(1)]
wordcloud(frequencyUnigramDF$word, frequencyUnigramDF$freq,scale = c(6,.6),colors =  pal,max.words = 300)

wordcloud(frequencyBigramDF$word, frequencyBigramDF$freq,scale = c(5,0.4),colors =  pal,max.words = 70)

wordcloud(frequencyTrigramDF$word, frequencyTrigramDF$freq,scale = c(3.5,0.2),colors =  pal,max.words = 45)


wordcloud(frequencyQuadgramDF$word, frequencyQuadgramDF$freq,scale = c(3.3,0.2),colors =  pal,max.words = 32)

kable(head(frequencyUnigramDF,20),caption = "All Unigram Frequency - Top 20")
summary(frequencyUnigramDF)

kable(head(frequencyBigramDF,20),caption = "All Bigram Frequency - Top 20")
summary(frequencyBigramDF)

kable(head(frequencyTrigramDF,20),caption = "All Trigram Frequency - Top 20")
summary(frequencyTrigramDF)
kable(head(frequencyQuadgramDF,20),caption = "All Quadgram Frequency - Top 20")
summary(frequencyQuadgramDF)

        

```

#Intrinsic Evaluation - Perplexity


Predicting the next word.  
###Create our Test Set

```{r createTestSet}
blogsTestMap <- buildTermMap("./data/en_US.blogs.test.txt")
twitterTestMap<- buildTermMap("./data/en_US.twitter.test.txt")
newsTestMap<- buildTermMap("./data/en_US.news.test.txt")
fullTestMap <- c(blogsTestMap,twitterTestMap,newsTestMap)
```

##Dealing with Zeros



