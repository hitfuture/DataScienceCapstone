---
title: "Task 1 - Data acquisition and cleaning"
author: "Brett Taylor"
date: "December 9, 2015"
output: word_document
---

#Data Acquisition
The data source is from the Coursera site.  https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip  There is a set of files in multiple languages.    
* Twitter
* News
* Blog Posts


#Clean Data - Remove Profanities
We need to ensure profanities are not allowed.   We utilized the Google What You Love data source captured by Jamie W. on GitHub to create a list of stop words.  The data source is here, and required some cleaning up since it did not meet JSON standards: https://gist.github.com/jamiew/1112488.   Note that this includes very profane words and should not be shared with people that will be offended.


```{r getBadWords}
library(RJSONIO)
library(tm)
curseStops  <- names(fromJSON("./data/google_twunter_lol.json"))
curseCorp <- VCorpus(VectorSource(curseStops))
print(sample(curseStops,100))
```

#Clean and Process Data
We need to tokenize the text based data.  

```{r writeCorpusDataSets,cache=TRUE}
library(tm)
source("sampleData.R")

writeCorpusDataSets("./data/en_US.blogs.txt")
writeCorpusDataSets("./data/en_US.news.txt")
writeCorpusDataSets("./data/en_US.twitter.txt")
```

```{r buildModel1}
source("runModel.R")
source("buildModel.R")


blogsTermMap <- buildTermMap("./data/en_US.blogs.valid.txt")
twitterTermMap<- buildTermMap("./data/en_US.twitter.valid.txt")
newsTermMap<- buildTermMap("./data/en_US.news.valid.txt")


```

#The need for spell checking

I think that when a user types in words into the window, they will need to have their word spell checked, and corrected to that predictions are accurate.  The corpus may have variation.

#Blog
 
```{r blogCloud}
    
library("RWeka")
library(wordcloud)
options(mc.cores=1)
map <- blogsTermMap
tdmap1  <- buildUnigramMap(map)
tdmap2  <- buildBigramMap(map)
tdmap3 <- buildTrigramMap(map)

d1 <- buildFrequencyDataSet(tdmap1)
d2 <- buildFrequencyDataSet(tdmap2)
d3 <- buildFrequencyDataSet(tdmap3)


#inspect(tdmap)
#object.size(tdmap)
head(d1)

head(d2)

head(d3)

pal <- brewer.pal(6,"Dark2")
pal <- pal[-(1)]
wordcloud(d1$word, d1$freq,scale = c(4,0.4),colors =  pal,max.words = 300)

wordcloud(d2$word, d2$freq,scale = c(4,0.4),colors =  pal,max.words = 100)

wordcloud(d3$word, d3$freq,scale = c(4,0.4),colors =  pal,max.words = 100)

```

##Twitter 

```{r twitterCloud}
    
map <- twitterTermMap
tdmap1  <- buildUnigramMap(map)
tdmap2  <- buildBigramMap(map)
tdmap3 <- buildTrigramMap(map)

d1 <- buildFrequencyDataSet(tdmap1)
d2 <- buildFrequencyDataSet(tdmap2)
d3 <- buildFrequencyDataSet(tdmap3)


#inspect(tdmap)
#object.size(tdmap)
head(d1)

head(d2)

head(d3)

pal <- brewer.pal(6,"Dark2")
pal <- pal[-(1)]
wordcloud(d1$word, d1$freq,scale = c(4,0.4),colors =  pal,max.words = 300)

wordcloud(d2$word, d2$freq,scale = c(4,0.4),colors =  pal,max.words = 100)

wordcloud(d3$word, d3$freq,scale = c(4,0.4),colors =  pal,max.words = 100)
```

##News

```{r newsCloud}
map <- newsTermMap
tdmap1  <- buildUnigramMap(map)
tdmap2  <- buildBigramMap(map)
tdmap3 <- buildTrigramMap(map)

d1 <- buildFrequencyDataSet(tdmap1)
d2 <- buildFrequencyDataSet(tdmap2)
d3 <- buildFrequencyDataSet(tdmap3)


#inspect(tdmap)
#object.size(tdmap)
head(d1)

head(d2)

head(d3)

pal <- brewer.pal(6,"Dark2")
pal <- pal[-(1)]
wordcloud(d1$word, d1$freq,scale = c(4,0.4),colors =  pal,max.words = 300)

wordcloud(d2$word, d2$freq,scale = c(4,0.4),colors =  pal,max.words = 100)

wordcloud(d3$word, d3$freq,scale = c(4,0.4),colors =  pal,max.words = 100)
   
```
